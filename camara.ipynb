{"cells":[{"cell_type":"markdown","metadata":{"id":"yVr7INRVefsB"},"source":["# **Vision por computadora**\n","\n","La detección de distintas partes del cuerpo humano especialmente el de las manos mediante algoritmos pueden ser útiles en diversas aplicaciones, como la implementación del control de gestos, la interpretación del lenguaje de señas o la mejora de soluciones para aplicaciones de realidad aumentada.\n","\n","MediaPipe es un marco que proporciona soluciones personalizables de aprendizaje automático (ML) (como detección de rostros y manos, segmentación del cabello, seguimiento de movimiento, etc.) para imagenes o video. Su solución para la detección y seguimiento de manos se llama MediaPipe Hands, y emplea ML para proporcionar detección de palma y un modelo de punto de referencia de mano que consta de 21 puntos de referencia 3D, como se muestra en la Figura 1.\n","\n","![manos](https://developers.google.com/static/mediapipe/images/solutions/hand-landmarks.png)\n","\n","Este mapa de la mano nos ayudara a guiarnos sobre los puntos guia de cada dedo de la mano.\n"]},{"cell_type":"markdown","metadata":{"id":"VCDNNpx2efsH"},"source":["# **Código**\n","\n","**Descarga y abre este archivo**\n","\n","Vamos a iniciar directamente con algo de código, nuestro trabajo ahora más que producir código es entenderlo, se añadio un comentario a cada linea."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"elapsed":8,"status":"error","timestamp":1697979712273,"user":{"displayName":"Pedro Llamoca","userId":"07941999638691434939"},"user_tz":300},"id":"25ZKerVtefsJ","outputId":"4d786835-10cd-4557-e528-ede168247ecf"},"outputs":[],"source":["#Primero ejecuta esta celda\n","\n","import cv2 # Biblioteca para procesar vision de imagenes o videos\n","import mediapipe as mp # Biblioteca para procesar partes del cuerpo humano usando inteligencia artificial\n","\n","\n","mp_drawing = mp.solutions.drawing_utils # se inicia una variable de mediapipe para usar dibujos sobre la pantalla\n","mp_drawing_styles = mp.solutions.drawing_styles # se inicia una variable de mediapipe para usar dibujos sobre las manos\n","mp_hands = mp.solutions.hands # se inicia una variable de mediapipe para detectar manos\n","cap = cv2.VideoCapture(0) # se inicia una variable de cv2 para usar las imagenes de la primera camara\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mdVNYpeLefsL"},"outputs":[],"source":["#Ahora ejecuta esta celda\n","\n","with mp_hands.Hands(model_complexity=1,min_detection_confidence=0.5,min_tracking_confidence=0.5) as hands: # configura mp_hands (with se utiliza para liberarla cuando no se use), complejidad del modelo, y confianza en la minima para detectar la mano y el seguimiento\n","  while cap.isOpened(): # mientras la camara este abierta\n","    existe, image = cap.read() # la camara devuelve dos valores existe (verdadero o falso) y la imagen de la camara (image)\n","    if not existe: # se comprueba si la camara esta presente (si existe es falso)\n","      print(\"Ignorando fotogramas si no hay camara\")\n","      break # si no hay camara se termina el bucle while\n","\n","    image=cv2.flip(image,1) # se invierte la imagen de manera horizontal\n","    imagen_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # se convierte la imagen a los colores RGB desde BGR\n","    results = hands.process(imagen_rgb) # Se procesan las imagenes en busqueda de manos y se guardan en results\n","\n","    if results.multi_hand_landmarks: # Si dentro de results existen marcas de referencia en las manos (en resumen si hay manos)\n","\n","      for hand_landmarks in results.multi_hand_landmarks: # para cada marca en todas las marcas de las manos\n","        mp_drawing.draw_landmarks(image,hand_landmarks,mp_hands.HAND_CONNECTIONS,) # se dibuja en la imagen las marcas de las manos y las conexiones entre ellas\n","\n","    cv2.putText(image,\"ESC para salir\",(5,450),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2) # se muestra un texto en las coordenas (5,540), fuente, tamaño, color (255,255,255) y grosor\n","    cv2.imshow('MediaPipe Manos', image) # se coloca un titulo en la ventana y se muestra la imagen de la camara procesada\n","    if cv2.waitKey(1) == 27: # se espera a que se presione la tecla ESC\n","      break # si se presiona la tecla escape se rompe el bucle while\n","cap.release() # se libera la camara\n","cv2.destroyAllWindows() # se elimina la ventana"]},{"cell_type":"markdown","metadata":{"id":"essyhM-defsM"},"source":["# Resuelve\n","\n","Una vez comprendido el funcionamiento básico de esta sección (pregunta si no entendiste alguna linea)\n","\n","- En la sección de código de abajo copia y pega ambas celdas de código, es decir, junta todo.\n","- Modifica el título de la ventana a \"Deteccion de manos\".\n","- Modifica el color del texto ESC para salir a amarillo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyryK1gkefsM"},"outputs":[],"source":["# Coloca el código debajo\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
